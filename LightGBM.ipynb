{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgbm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import sys\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "\n",
    "raw_dir = \"/home/ec2-user/pwp-summer-2019/master_thesis_nhh_2019/raw_data/\" \n",
    "data_dir = \"/home/ec2-user/pwp-summer-2019/master_thesis_nhh_2019/processed_data/\" \n",
    "\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class feature_engineering from the file \"Functions\"\n",
    "from Functions import (feature_engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(data_dir+'df_train')\n",
    "df_val = pd.read_pickle(data_dir+'df_val')\n",
    "df_test = pd.read_pickle(data_dir+'df_test')\n",
    "\n",
    "formation_dictionary = joblib.load(data_dir+'formation_dictionary.pkl')\n",
    "\n",
    "df_train_val = df_train.append(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_features = {\n",
    "    'outlier_values': {'gr': df_train_val.gr.quantile(0.9995),\n",
    "                       'rmed': df_train_val.rmed.quantile(0.9995),\n",
    "                        'rdep': df_train_val.rdep.quantile(0.9995)\n",
    "                      },\n",
    "    'above_below_variables': ['gr','rdep','rmed'],\n",
    "    'y_variable': 'formation_2',\n",
    "    'num_shifts': 1,\n",
    "    'cols_to_remove' : ['depth', 'dts','hgr', 'hnphi', \n",
    "                        'hrdep', 'hrhob', 'hrmed', 'hrsh','rsh','field','main_area','md'],\n",
    "    'thresh': 7,\n",
    "    'var1_ratio': 'gr'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For home-made stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class = feature_engineering(df_train,**params_features)\n",
    "\n",
    "train_class.remove_outliers()\n",
    "train_class.above_below()\n",
    "train_class.cleaning()\n",
    "train_class.xyz()\n",
    "\n",
    "df_train = train_class.df\n",
    "columns_class = df_train.columns\n",
    "\n",
    "val_class = feature_engineering(df_val,**params_features)\n",
    "\n",
    "val_class.remove_outliers()\n",
    "val_class.above_below()\n",
    "val_class.cleaning()\n",
    "val_class.xyz()\n",
    "df_val = val_class.df[columns_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For sklearn(randomized) stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = feature_engineering(df_train_val,**params_features)\n",
    "\n",
    "df_class.remove_outliers()\n",
    "df_class.above_below()\n",
    "df_class.cleaning()\n",
    "df_class.xyz()\n",
    "\n",
    "df = df_class.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train_valid/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For home-made stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['formation','title','formation_2','group']\n",
    "X_train = df_train.drop(col, axis=1)\n",
    "Y_train = df_train['formation_2']\n",
    "\n",
    "X_valid = df_val.drop(col, axis=1)\n",
    "Y_valid = df_val['formation_2']\n",
    "\n",
    "features_list = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For sklearn(randomized) stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['formation','title','formation_2','group']\n",
    "X = df.drop(col, axis=1)\n",
    "y = df['formation_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_and_valid, X_test, Y_train_and_valid, Y_test = train_test_split( X, y, \n",
    "                                                                        test_size=0.10, \n",
    "                                                                        random_state=42, \n",
    "                                                                        stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_and_valid, Y_train_and_valid, \n",
    "                                                      test_size=0.33, \n",
    "                                                      random_state=42, \n",
    "                                                      stratify=Y_train_and_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(Y_train),Y_train)\n",
    "class_weights_dict=dict(zip(np.unique(Y_train), class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_train, Y_train), (X_valid, Y_valid)]\n",
    "\n",
    "# Tuning from Bayesian\n",
    "model_lightgbm = lgbm.LGBMClassifier(boosting_type='gbdt',\n",
    "                            learning_rate = 0.05,\n",
    "                            num_leaves = 5,\n",
    "                            n_estimators = 500, \n",
    "                            boost_from_average = False,\n",
    "                            silent = False,\n",
    "                            max_depth =  90, #12\n",
    "                            class_weight=class_weights_dict,\n",
    "                            feature_fraction= 1,\n",
    "                            min_data_in_leaf = 657,\n",
    "                            random_state = 42\n",
    "                                             )\n",
    "\n",
    "model_lightgbm.fit(X = X_train, y = Y_train,\n",
    "         eval_set = eval_set,\n",
    "         early_stopping_rounds= 50,\n",
    "         eval_metric= 'multi_logloss',\n",
    "         verbose = 10\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(model_lightgbm, 'lgbm_model.pkl')\n",
    "# Load model\n",
    "#model_lightgbm = joblib.load('lgbm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize training and validation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model_lightgbm.evals_result_['training']['multi_logloss']).plot()\n",
    "pd.Series(model_lightgbm.evals_result_['valid_1']['multi_logloss']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compute test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def predict_and_post_process(data_,real_values,formation_code,model_, \n",
    "                             features_list_, result, test_data = 'no'):\n",
    "    data = data_.copy()\n",
    "    \n",
    "    if result == 'light_gbm':\n",
    "    \n",
    "        train_predict = model_.predict(data)\n",
    "        train_predict_df = pd.DataFrame(train_predict)\n",
    "        #train_predict_df['target_lgbm'] = train_predict_df.values\n",
    "        #train_predict_df = pd.DataFrame(train_predict)\n",
    "        train_predict_df['target_lgbm'] = train_predict_df.idxmax(axis=1)\n",
    "    \n",
    "    elif result == 'grid_result':\n",
    "        train_predict = model_.predict(data)\n",
    "        train_predict_df = pd.DataFrame(train_predict)\n",
    "        #train_predict_df['target_lgbm'] = train_predict_df.values\n",
    "        #train_predict_df = pd.DataFrame(train_predict)\n",
    "        train_predict_df['target_lgbm'] = train_predict_df\n",
    "        \n",
    "    if test_data == 'yes':\n",
    "        f1 = metrics.f1_score(train_predict_df['target_lgbm'], real_values, average='micro')\n",
    "        print ('f1 score is: ', f1)\n",
    "    \n",
    "\n",
    "    test_df = pd.DataFrame(data)\n",
    "    test_df['target_lgbm'] = train_predict_df['target_lgbm'].values\n",
    "    test_df['target'] = real_values.values\n",
    "    \n",
    "    print ('total points:', len(test_df))\n",
    "    test_df['predicted_formation'] = test_df['target_lgbm'].map(formation_code)\n",
    "    \n",
    "    if type(list(real_values)[0]) == int:\n",
    "        f1 = metrics.f1_score(train_predict_df['target_lgbm'], real_values, average='micro')\n",
    "        print ('f1 score is: ', f1)\n",
    "        test_df['real_formation'] = test_df['target'].map(formation_code)\n",
    "        print ('Number of points not matching: ', \n",
    "               len(test_df.loc[~(test_df['real_formation'] == test_df['predicted_formation'])]))\n",
    "\n",
    "    else:\n",
    "        test_df['real_formation'] = test_df['target'].values\n",
    "        \n",
    "        f1 = metrics.f1_score(test_df['predicted_formation'], real_values, average='micro')\n",
    "        print ('f1 score is: ', f1)\n",
    "        print ('Number of points not matching: ', \n",
    "               len(test_df.loc[~(test_df['real_formation'] == test_df['predicted_formation'])]))\n",
    "        print ('---------------------------------')\n",
    "        \n",
    "    if test_data == 'no':\n",
    "        print ('Point in real formation: \\n', test_df['real_formation'].value_counts())\n",
    "        print ('Point in predicted formation: \\n', test_df['predicted_formation'].value_counts())\n",
    "    \n",
    "    #new_cols=['ac', 'den', 'gr', 'neu', 'rdep', 'rmed', 'tvd','x','y','z']\n",
    "    test_df.rename(columns=dict(zip(test_df.columns[:len(features_list_)], \n",
    "                                    features_list_)),inplace=True)\n",
    "    \n",
    "    return test_df, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_wells = df_test.title.unique()\n",
    "\n",
    "test_class = feature_engineering(df_test,**params_features)\n",
    "\n",
    "test_class.above_below()\n",
    "test_class.thresh = 0 # In order to not remove any rows when cleaning\n",
    "test_class.cleaning()\n",
    "test_class.xyz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_well = test_class.df.copy()\n",
    "\n",
    "XX = exp_well.drop(col,axis = 1).values\n",
    "yy = exp_well['formation_2']\n",
    "\n",
    "print ('-----------')\n",
    "blind_data_prediction, f1 = predict_and_post_process(XX,yy,formation_dictionary,model_lightgbm,\n",
    "                                                     features_list, 'grid_result') ## for grid result model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to data set - Not stratified\n",
    "test_df = test_class.df\n",
    "test_df['predicted'] = blind_data_prediction.target_lgbm\n",
    "\n",
    "#test_df.to_pickle('blind_test_lgbm_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on individual wells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_wells = df_test.title.unique()\n",
    "test_class = feature_engineering(df_test,**params_features)\n",
    "\n",
    "test_class.above_below()\n",
    "test_class.thresh = 0 # In order to not remove any rows when cleaning\n",
    "test_class.cleaning()\n",
    "test_class.xyz()\n",
    "\n",
    "test_df = test_class.df\n",
    "\n",
    "results = {}\n",
    "\n",
    "for well in blind_wells:\n",
    "\n",
    "    exp_well = test_class.df[test_class.df.title == well].copy() \n",
    "\n",
    "    XX = exp_well.drop(col,axis = 1).values\n",
    "    yy = exp_well['formation_2']\n",
    "\n",
    "    print ('-----------')\n",
    "    blind_data_prediction, f1 = predict_and_post_process(XX,yy,formation_dictionary,model_lightgbm,\n",
    "                                      features_list, 'grid_result') ## for grid result model\n",
    "    results[well] = f1\n",
    "    blind_data_prediction\n",
    "\n",
    "print ('\\n-----------')\n",
    "f1_values = []\n",
    "for key, values in results.items():\n",
    "    f1_values.append(values)\n",
    "print('Mean of all wells:',np.mean(f1_values))\n",
    "print ('-----------')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# explain the model's predictions using SHAP values\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "explainer = shap.TreeExplainer(model_lightgbm)\n",
    "shap_values = explainer.shap_values(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Feature Importance for \"well x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TO CHOOSE COLORPALATE: https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "#shap.summary_plot(shap_values, X, plot_type=\"dot\",color=pl.get_cmap(\"tab10\"))\n",
    "\n",
    "shap.summary_plot(shap_values, XX,\n",
    "                  feature_names = features_list, \n",
    "                  plot_type   = \"bar\", \n",
    "                  max_display = None,\n",
    "                  plot_size   = (12,10),#'auto',\n",
    "                  class_names = list(formation_dictionary.values()),\n",
    "                  color       = plt.get_cmap(\"tab20\")\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance for specific class\n",
    "\n",
    "What feature levels drove our predicitons twoards predicting the given class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[29], XX, feature_names=features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
